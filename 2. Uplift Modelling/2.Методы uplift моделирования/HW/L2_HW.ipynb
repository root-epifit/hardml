{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417238a-7b72-4e38-8dbd-d2438147d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 ДЗ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fe504c-b551-4170-bb70-b3ee6a4d647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "example_X = np.load('./data/example_X.npy')\n",
    "example_Y = np.load('./data/example_y.npy')\n",
    "example_T = np.load('./data/example_treatment.npy')\n",
    "example_preds = np.load('./data/example_preds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a23fb6f-50ce-48e3-8fc4-b5def2283250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Iterable, Tuple, List\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, depth:int = 0, parent: object = None, node_type: str = 'Root'):\n",
    "        #self.predicted_class = predicted_class\n",
    "        self._n_items = 0\n",
    "        self._depth = depth\n",
    "        self._type = node_type\n",
    "        self._ate = 0\n",
    "        self._split_feat = None\n",
    "        self._split_threshold = None\n",
    "        self._parent = None\n",
    "        self._left = None\n",
    "        self._right = None\n",
    "\n",
    "    def print(self):\n",
    "        print(\"\")\n",
    "        print(f\"node_id        = {self}\")\n",
    "        print(f\"depth          = {self._depth}\")\n",
    "        print(f\"type           = {self._type}\")\n",
    "        print(f\"n_items        = {self._n_items}\")\n",
    "        print(f\"ATE            = {self._ate}\")\n",
    "        print(f\"split_feat     = {self._split_feat}\")\n",
    "        print(f\"split_threshold= {self._split_threshold}\")\n",
    "        print(f\"parent         = {self._parent}\")\n",
    "        print(f\"left           = {self._left}\")\n",
    "        print(f\"right          = {self._right}\")\n",
    "        \n",
    "         \n",
    "class UpliftTreeRegressor: \n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: int = 3, # максимальная глубина дерева.\n",
    "        min_samples_leaf: int = 1000, # минимальное необходимое число обучающих объектов в листе дерева.\n",
    "        min_samples_leaf_treated: int = 300, # минимальное необходимое число обучающих объектов с T=1 в листе дерева.\n",
    "        min_samples_leaf_control: int = 300, # минимальное необходимое число обучающих объектов с T=0 в листе дерева.\n",
    "    ) -> None:\n",
    "        # do something\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_leaf = min_samples_leaf\n",
    "        self._min_samples_leaf_treated = min_samples_leaf_treated\n",
    "        self._min_samples_leaf_control = min_samples_leaf_control\n",
    "        self._root_node = None\n",
    "        \n",
    "    def fit(\n",
    "        self,\n",
    "        X: np.ndarray,         # массив (n * k) с признаками.\n",
    "        treatment: np.ndarray, # массив (n) с флагом воздействия.\n",
    "        y: np.ndarray          # массив (n) с целевой переменной.\n",
    "    ) -> None:\n",
    "        # fit the model\n",
    "        self._root_node = Node(depth=0)\n",
    "        self._build_tree(self._root_node, X, y, treatment)\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> Iterable[float]:\n",
    "        # compute predictions\n",
    "        if self._root_node is None:\n",
    "            raise ValueError(f'{self.__class__.__name__} is not fitted. Please use .fit() first.')\n",
    "        return [self._predict(x) for x in X]\n",
    "    \n",
    "    def _predict(self, x: np.array) -> float:\n",
    "        # Предсказание для отдного наблюдения x из X\n",
    "        node = self._root_node\n",
    "        while node._left:\n",
    "            if x[node._split_feat] <= node._split_threshold:\n",
    "                node = node._left\n",
    "            else:\n",
    "                node = node._right\n",
    "        return node._ate\n",
    "     \n",
    "    def _get_threshold_options(self, column_values: List[float]) -> List[float]:\n",
    "        unique_values = np.unique(column_values)\n",
    "        if len(unique_values) > 10:\n",
    "            percentiles = np.percentile(column_values, [3, 5, 10, 20, 30, 50, 70, 80, 90, 95, 97])\n",
    "        else:\n",
    "            percentiles = np.percentile(unique_values, [10, 50, 90])\n",
    "        return np.unique(percentiles)\n",
    "\n",
    "    def _is_satisfy_constraints(self, t) -> bool:\n",
    "        min_samples, min_treated, min_control =  self._min_samples_leaf, self._min_samples_leaf_treated, self._min_samples_leaf_control\n",
    "        samples = t.shape[0]\n",
    "        treated = t[(t == 1)].shape[0]\n",
    "        control = t[(t == 0)].shape[0]\n",
    "        return (samples >= min_samples) and (treated >= min_treated) and (control >= min_control)\n",
    "        \n",
    "    def _best_split_on_axis(self,\n",
    "                    X: np.array = None, \n",
    "                    y:np.array = None, \n",
    "                    t:np.array = None) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Возвращает лучший порог  и значение критерия для массива X - среза n-й фичи\n",
    "        \"\"\"\n",
    "    \n",
    "        # Получаем список возможных порогов\n",
    "        threshold_options = self._get_threshold_options(X)\n",
    "    \n",
    "        # Итерируемся по списку возможных порогов и для каждого вычисляем delta_delta_p\n",
    "        deltas = []\n",
    "        for threshold in threshold_options:\n",
    "            mask = (X <= threshold)\n",
    "\n",
    "            X_left, y_left, t_left = X[mask], y[mask], t[mask]\n",
    "            X_right, y_right, t_right = X[~mask], y[~mask], t[~mask]\n",
    "\n",
    "            if self._is_satisfy_constraints(t_left) and self._is_satisfy_constraints(t_right):\n",
    "                # разбиение удовлетворяет граничным условиям\n",
    "                uplift_left = self._uplift(y_left, t_left)\n",
    "                uplift_right = self._uplift(y_right, t_right)\n",
    "                delta_delta_p = abs(uplift_left - uplift_right)\n",
    "            else:\n",
    "                # разбиение не удовлетворяет граничным условиям => исклюбчаем его из расмотрения\n",
    "                # print(f\"_best_split_on_axiы: разбиение не удовлетворяет граничным  условиям, treshold={threshold}\")\n",
    "                delta_delta_p = -1\n",
    "            deltas.append(delta_delta_p)\n",
    " \n",
    "        # находим порог, который дает макс.значение критерия\n",
    "        deltas = np.array(deltas)\n",
    "        delta_delta_p = deltas.max()\n",
    "        threshold = threshold_options[(deltas == delta_delta_p)][0]\n",
    "    \n",
    "        return threshold, delta_delta_p\n",
    "\n",
    "\n",
    "    def _best_split(self, X:np.ndarray, y:np.array, t:np.array) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        Для матрицы наблюдений возвращает наилучшее разбиение, возвращает:\n",
    "        - split_feat - индекс фактора по которому производить разбиение\n",
    "        - split_threshold - порог\n",
    "        \"\"\"\n",
    "\n",
    "        result = []\n",
    "        n_feats = X.shape[1]\n",
    "        for feature_idx in range(n_feats):\n",
    "            threshold, delta_delta_p = self._best_split_on_axis(X[:,feature_idx], y, t)\n",
    "            result.append([feature_idx, threshold, delta_delta_p])    \n",
    "        result = np.array(result)\n",
    "\n",
    "        mask = (result[:,2] == result.max(axis=0)[2])   # байтовая маска для строки с макс.значением delta_delta_p\n",
    "        split_feat, split_threshold = result[mask][0].tolist()[:2] # отбираем строку\n",
    "    \n",
    "        return int(split_feat), split_threshold\n",
    "        \n",
    "\n",
    "    def _uplift(self, y, t) -> float:\n",
    "        mask = (t == 1)\n",
    "        y_c, t_c = y[~mask],  t[~mask]\n",
    "        y_t, t_t = y[mask], t[mask]\n",
    "    \n",
    "        t_value = (y_t * t_t).sum()\n",
    "        t_sum   = t_t.sum()\n",
    "\n",
    "        c_value = (y_c * (1-t_c)).sum()\n",
    "        c_sum   = (1-t_c).sum() \n",
    "\n",
    "        t_value_mean = 0 if t_sum == 0 else t_value/t_sum\n",
    "        c_value_mean = 0 if c_sum == 0 else c_value/c_sum\n",
    "         \n",
    "        return t_value_mean - c_value_mean\n",
    "    \n",
    "\n",
    "    def _ate(self, y,t) -> float:\n",
    "        y_mean_t = y[(t == 1)].mean()\n",
    "        y_mean_c = y[(t == 0)].mean()\n",
    "        return y_mean_t - y_mean_c\n",
    "    \n",
    "    \n",
    "    def _build_tree(self,\n",
    "                   node:Node,\n",
    "                   X: np.ndarray = None, \n",
    "                   y:np.array = None, \n",
    "                   t:np.array = None) -> None:\n",
    "    \n",
    "        max_depth = self._max_depth\n",
    "        next_node_depth = node._depth + 1\n",
    "        \n",
    "        node._n_items = X.shape[0]\n",
    "        node._split_feat, node._split_threshold = self._best_split(X, y, t)\n",
    "        node._ate = self._ate(y,t)\n",
    "\n",
    "        mask = (X[:,node._split_feat] <= node._split_threshold)\n",
    "                \n",
    "        X_left, y_left, t_left = X[mask], y[mask], t[mask]\n",
    "        X_right, y_right, t_right = X[~mask], y[~mask], t[~mask]\n",
    "        \n",
    "        if  next_node_depth <= max_depth:\n",
    "            # Глубина дерева не превышена, можно создавать новый узел\n",
    "            if self._is_satisfy_constraints(t_left):\n",
    "                node._left = Node(depth=next_node_depth, parent=node, node_type='Left')\n",
    "                self._build_tree(node._left, X_left, y_left, t_left)\n",
    "\n",
    "            if self._is_satisfy_constraints(t_right):\n",
    "                node._right = Node(depth=node._depth+1, parent=node, node_type='Right')\n",
    "                self._build_tree(node._right, X_right, y_right, t_right)\n",
    "\n",
    "        #node.print()\n",
    "        \n",
    "        return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e01c535-418c-4dae-be77-9fdb8a068b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7590322044259551,\n",
       " 0.7590322044259551,\n",
       " 0.7590322044259551,\n",
       " 0.7590322044259551,\n",
       " 2.499740934854509,\n",
       " 0.7590322044259551,\n",
       " 0.7590322044259551,\n",
       " 0.7590322044259551,\n",
       " 0.7590322044259551,\n",
       " 0.7590322044259551]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тестирование\n",
    "n_samples = example_X.shape[0]\n",
    "X=example_X[:n_samples,]\n",
    "y=example_Y[:n_samples]\n",
    "t=example_T[:n_samples]\n",
    "\n",
    "tree = UpliftTreeRegressor()\n",
    "\n",
    "tree.fit(X,t,y)\n",
    "tree.predict(X[10:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b457aca1-b665-4fe8-b405-0e30905b9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Черновики\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a05fa5-68ab-4ee4-b070-b898833c4c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_threshold_options(column_values: List[float]) -> List[float]:\n",
    "    unique_values = np.unique(column_values)\n",
    "    if len(unique_values) > 10:\n",
    "        percentiles = np.percentile(column_values, [3, 5, 10, 20, 30, 50, 70, 80, 90, 95, 97])\n",
    "    else:\n",
    "        percentiles = np.percentile(unique_values, [10, 50, 90])\n",
    "    return np.unique(percentiles)\n",
    "\n",
    "#def _calc_uplift(X: List[float, float], y: List[float]) -> float:\n",
    "#    print(f\"_calc_uplift\")\n",
    "\n",
    "#for column in range(example_X.shape[1]):\n",
    "#    column_values = example_X[:,column]\n",
    "#    print(f\"column = {column}, threshold = {_get_threshold_options(column_values)}\\n\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72cfa3-aebb-4313-a9ba-0de83dc1a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, depth:int = 0, parent: Node = None, node_type: str = 'Root'):\n",
    "        #self.predicted_class = predicted_class\n",
    "        self._n_items = 0\n",
    "        self._depth = depth\n",
    "        self._type = node_type\n",
    "        self._ate = 0\n",
    "        self._split_feat = None\n",
    "        self._split_threshold = None\n",
    "        self._parent = None\n",
    "        self._left = None\n",
    "        self._right = None\n",
    "\n",
    "    def print(self):\n",
    "        print(\"\")\n",
    "        print(f\"node_id        = {self}\")\n",
    "        print(f\"depth          = {self._depth}\")\n",
    "        print(f\"type           = {self._type}\")\n",
    "        print(f\"n_items        = {self._n_items}\")\n",
    "        print(f\"ATE            = {self._ate}\")\n",
    "        print(f\"split_feat     = {self._split_feat}\")\n",
    "        print(f\"split_threshold= {self._split_threshold}\")\n",
    "        print(f\"parent         = {self._parent}\")\n",
    "        print(f\"left           = {self._left}\")\n",
    "        print(f\"right          = {self._right}\")\n",
    "\n",
    "def _is_satisfy_constraints(t, min_samples, min_treated, min_control) -> bool:\n",
    "    samples = t.shape[0]\n",
    "    treated = t[(t == 1)].shape[0]\n",
    "    control = t[(t == 0)].shape[0]\n",
    "    return (samples >= min_samples) and (treated >= min_treated) and (control >= min_control)\n",
    "        \n",
    "def _best_split_on_axis(X: np.array = None, \n",
    "                y:np.array = None, \n",
    "                t:np.array = None) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Возвращает лучший порог  и значение критерия для массива X - среза n-й фичи\n",
    "    \"\"\"\n",
    "    \n",
    "    # Получаем список возможных порогов\n",
    "    threshold_options = _get_threshold_options(X)\n",
    "    \n",
    "    # Итерируемся по списку возможных порогов и для каждого вычисляем delta_delta_p\n",
    "    deltas = []\n",
    "    for threshold in threshold_options:\n",
    "        mask = (X <= threshold)\n",
    "\n",
    "        X_left, y_left, t_left = X[mask], y[mask], t[mask]\n",
    "        X_right, y_right, t_right = X[~mask], y[~mask], t[~mask]\n",
    "\n",
    "        if _is_satisfy_constraints(t_left, 6000, 2500, 2500) and _is_satisfy_constraints(t_right, 6000, 2500, 2500):\n",
    "            # разбиение удовлетворяет граничным условиям\n",
    "            uplift_left = _uplift(y_left, t_left)\n",
    "            uplift_right = _uplift(y_right, t_right)\n",
    "            delta_delta_p = abs(uplift_left - uplift_right)\n",
    "        else:\n",
    "            # разбиение не удовлетворяет граничным условиям => исклюбчаем его из расмотрения\n",
    "            # print(f\"_best_split_on_axiы: разбиение не удовлетворяет граничным  условиям, treshold={threshold}\")\n",
    "            delta_delta_p = -1\n",
    "        deltas.append(delta_delta_p)\n",
    " \n",
    "    # находим порог, который дает макс.значение критерия\n",
    "    deltas = np.array(deltas)\n",
    "    delta_delta_p = deltas.max()\n",
    "    threshold = threshold_options[(deltas == delta_delta_p)][0]\n",
    "    \n",
    "    return threshold, delta_delta_p\n",
    "\n",
    "\n",
    "def _best_split(X:np.ndarray, y:np.array, t:np.array) -> Tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Для матрицы наблюдений возвращает наилучшее разбиение, возвращает:\n",
    "    - split_feat - индекс фактора по которому производить разбиение\n",
    "    - split_threshold - порог\n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "    n_feats = X.shape[1]\n",
    "    for feature_idx in range(n_feats):\n",
    "        threshold, delta_delta_p = _best_split_on_axis(X[:,feature_idx], y, t)\n",
    "        result.append([feature_idx, threshold, delta_delta_p])    \n",
    "    result = np.array(result)\n",
    "\n",
    "    mask = (result[:,2] == result.max(axis=0)[2])   # байтовая маска для строки с макс.значением delta_delta_p\n",
    "    split_feat, split_threshold = result[mask][0].tolist()[:2] # отбираем строку\n",
    "    \n",
    "    return int(split_feat), split_threshold\n",
    "        \n",
    "\n",
    "def _uplift(y, t) -> float:\n",
    "    mask = (t == 1)\n",
    "    y_c, t_c = y[~mask],  t[~mask]\n",
    "    y_t, t_t = y[mask], t[mask]\n",
    "    \n",
    "    t_value = (y_t * t_t).sum()\n",
    "    t_sum   = t_t.sum()\n",
    "\n",
    "    c_value = (y_c * (1-t_c)).sum()\n",
    "    c_sum   = (1-t_c).sum() \n",
    "\n",
    "    t_value_mean = 0 if t_sum == 0 else t_value/t_sum\n",
    "    c_value_mean = 0 if c_sum == 0 else c_value/c_sum\n",
    "         \n",
    "    return t_value_mean - c_value_mean\n",
    "    \n",
    "\n",
    "def _ate(y,t) -> float:\n",
    "    y_mean_t = y[(t == 1)].mean()\n",
    "    y_mean_c = y[(t == 0)].mean()\n",
    "    return y_mean_t - y_mean_c\n",
    "    \n",
    "    \n",
    "def _build_tree(node:Node, \n",
    "           X: np.ndarray = None, \n",
    "           y:np.array = None, \n",
    "           t:np.array = None, \n",
    "           max_depth:int = 3) -> None:\n",
    "    \n",
    "    if  (node._depth == max_depth):\n",
    "        #print(\"\")\n",
    "        #print(f\"_biuld_tree: finishing... \\nnode._depth = {node._depth}, samples={X.shape[0]}, treated={t[(t==1)].shape[0]}, control={t[(t==0)].shape[0]}\")     \n",
    "        return\n",
    "    else:\n",
    "        node._n_items = X.shape[0]\n",
    "        node._split_feat, node._split_threshold = _best_split(X, y, t)\n",
    "        node._ate = _ate(y,t)\n",
    "\n",
    "        mask = (X[:,node._split_feat] <= node._split_threshold)\n",
    "                \n",
    "        X_left, y_left, t_left = X[mask], y[mask], t[mask]\n",
    "        X_right, y_right, t_right = X[~mask], y[~mask], t[~mask]\n",
    "        \n",
    "        if _is_satisfy_constraints(t_left, 6000, 2500, 2500):\n",
    "            node._left = Node(depth=node._depth+1, parent=node, node_type='Left')\n",
    "            _build_tree(node._left, X_left, y_left, t_left)\n",
    "\n",
    "        if _is_satisfy_constraints(t_right, 6000, 2500, 2500):\n",
    "            node._right = Node(depth=node._depth+1, parent=node, node_type='Right')\n",
    "            _build_tree(node._right, X_right, y_right, t_right)\n",
    "\n",
    "        node.print()\n",
    "        \n",
    "        return      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d25920-c90e-4a96-ac95-469165db4d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n_samples = 100\n",
    "n_samples = example_X.shape[0]\n",
    "X=example_X[:n_samples,]\n",
    "y=example_Y[:n_samples]\n",
    "t=example_T[:n_samples]\n",
    "\n",
    "#_best_split(X, y, t)\n",
    "\n",
    "#_best_split_on_axis(X[:,0], y, t)\n",
    "\n",
    "root = Node(depth=0)\n",
    "_build_tree(root, X, y, t, max_depth=3)\n",
    "\n",
    "#feature_index = 1\n",
    "#split_threshold = 0.03692346\n",
    "\n",
    "#mask = (X[:,feature_index] <= split_threshold)\n",
    "#mask\n",
    "\n",
    "#_uplift(y,t)\n",
    "\n",
    "#X[(X[:,0] <= 1.869800250289363)].shape, X[(X[:,0] <= 0.8428329389786856)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cbbf2-8cc6-49f3-b532-56bbd2e1ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.842832938978685\n",
    "#threshold = 1.869800250289363\n",
    "mask = (X[:,0] > threshold )\n",
    "treated = t[mask][(t[mask] == 1)]\n",
    "control = t[mask][(t[mask] == 0)]\n",
    "treated.shape, control.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5b3fc-f9fa-45f1-8601-20f679479d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение с образцом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caab3a5-98b2-462b-865c-baa16f88a9a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array([0.170\n",
    ",0.192\n",
    ",0.423\n",
    ",0.445\n",
    ",0.496\n",
    ",0.622\n",
    ",0.700\n",
    ",0.784\n",
    ",0.789\n",
    ",0.838\n",
    ",1.166\n",
    ",1.413\n",
    ",1.378\n",
    ",1.522\n",
    ",1.541\n",
    ",1.553\n",
    ",1.558\n",
    ",1.788\n",
    ",2.019\n",
    ",1.971\n",
    "#,2.180\n",
    "])\n",
    "\n",
    "t =np.array( [0\n",
    ",1\n",
    ",1\n",
    ",1\n",
    ",0\n",
    ",1\n",
    ",1\n",
    ",1\n",
    ",1\n",
    ",1\n",
    ",0\n",
    ",1\n",
    ",0\n",
    ",1\n",
    ",0\n",
    ",0\n",
    ",0\n",
    ",1\n",
    ",1\n",
    ",0\n",
    "#,1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd875e-493e-49d7-92e8-6dc92de4e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (t == 1)\n",
    "y_c, t_c = y[~mask],  t[~mask]\n",
    "y_t, t_t = y[mask], t[mask]\n",
    "    \n",
    "t_value = (y_t * t_t).sum()\n",
    "t_sum   = t_t.sum()\n",
    "\n",
    "c_value = (y_c * (1-t_c)).sum()\n",
    "c_sum   = (1-t_c).sum()\n",
    "     \n",
    "t_value/t_sum - c_value/c_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0eefd-d2a3-4d07-9767-ea1f9aba3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c7c23-001b-4b10-9dd1-541cabb9d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f731f-be3f-4348-ada2-6cfd40592843",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t.sum()/t_sum - y_c.sum()/c_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1e824-1dbd-4cb7-8c70-802b93d5b80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (t == 1)\n",
    "y_c, t_c = y[~mask], t[~mask]\n",
    "y_t, t_t = y[mask], t[mask]\n",
    "    \n",
    "t_value = (y_t * t_t).sum()\n",
    "t_sum   = t_t.sum()\n",
    "    \n",
    "c_value = (y_c * (1-t_c)).sum()\n",
    "c_sum   = (1-t_c).sum()\n",
    "    \n",
    "abs(t_value/t_sum - c_value/c_sum)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
