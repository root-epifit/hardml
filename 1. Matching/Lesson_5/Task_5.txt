Введение
В предложенном задании необходимо реализовать архитектуру KNRM, подготовить данные для обучения и написать пайплайн тренировки модели. Домашняя работа включает в себя как работу с простыми текстовыми эмбеддингами, так и детали имплементации архитектуры. В силу сложности и объёма эта работа приурочена сразу к двум лекциям (5 и 7).

Как и раньше, к заданию прилагается шаблон выполнения — детально сопоставьте его части с инструкцией, данной ниже, разберитесь в уже написанном коде и реализованных методах. Написанный код менять не нужно (скорее всего в таком случае вы не сможете пройти проверку автоматической системы). Все необходимые импорты уже сделаны.

В качестве датасета будет использоваться набор из пар вопросов с сайта Quora, где указано, является ли один из вопросов дубликатом другого. Это задача бинарной классификации. В качестве кандидатов брались максимально похожие вопросы, после чего производилась разметка. В рамках домашней работы по ранжированию будет решаться не задача определения дубликатов, а задача нахождения максимально похожих (т.е. релевантных) вопросов, которые могут удовлетворить пользователя ещё на этапе формулировки. Это можно рассматривать как suggest-систему, расположенную под плашкой "возможно, эти вопросы помогут вам". Поэтому введём три уровня релевантности:

2 — вопрос является полным дубликатом (согласно оригинальной разметке, это пары с таргетом, равным 1)

1 — вопрос очень похож на исходный, однако не является полным дубликатом (согласно оригинальной разметке, это пары с таргетом, равным 0)

0 — вопрос не похож на исходный, нерелевантный (таких пар в датасете нет, их можно нагенерировать самостоятельно из общего корпуса всех вопросов)

Этот датасет Quora Question Pairs (QQP) входит в набор датасетов GLUE, используемый для всесторонней оценки моделей машинного обучения, связанных с текстом. Скачать его можно на сайте или непосредственно по ссылке. В архиве лежат три файла: train используется для тренировки модели, dev применяется для оценки в рамках домашней работы, test на данном этапе не используется. 

В качестве текстовых эмбеддингов будут использоваться вектора GloVe 6B. Ознакомиться с особенностями этих эмбеддингов вы можете на официальном сайте, а вот точная ссылка на скачивание. В архиве представлены вектора разной размерности, однако для проверки работоспособности и оценки решения будут использоваться исключительно вектора размерности 50 (файл glove.6B.50d.txt внутри архива). Если вы малознакомы с эмбеддингами, то в 7-й лекции вы узнаете о них больше (в частности о необходимости предобработки текстов и про зависимость количества информации от размерности эмбеддинга). Понятно, что можно получить более высокое качество (вероятно, незначительно более высокое), используя эмбеддинги размерности 300. Однако это накладывает ограничения на ресурсы (память на диске и ОЗУ), время работы алгоритма и т.д. 