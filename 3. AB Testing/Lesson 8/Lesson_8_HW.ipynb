{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fcc15fe4-53e8-466c-8e09-26d51bd9427a",
   "metadata": {},
   "source": [
    "Задача. Класс для последовательного тестирования.\n",
    "Нужно написать класс для последовательного тестирования гипотезы о равенстве средних для случая простой основной гипотезы и простой альтернативной гипотезы.\n",
    "\n",
    "Класс должен иметь два метода:\n",
    "\n",
    "run_test: запуск теста по всем имеющимся данным с начала пилота.\n",
    "add_data: проверка теста на основании добавленных ранее данных и новых данных.\n",
    "Пример:\n",
    "\n",
    "Допустим, у нас есть высокочастотный источник данных. Данные из эксперимента поступают каждые 10 минут. Через час после начала эксперимента мы решили посмотреть, достаточно ли информации для принятия решения. Для этого мы инициализируем объект класса SequentialTester и вызываем метод run_test, куда передаём все накопленные за первый час данные. Данных оказалось недостаточно, нужно продолжать эксперимент. Выгружать каждый раз все данные с самого начала эксперимента может быть ресурсозатратно, поэтому далее будем пользоваться методом add_data. При каждом поступлении новых данных будем вызывать метод add_data, в который будем передавать только новые данные. Результат метода add_data должен быть посчитан на основании новых данных, которые ему были переданы, и всех ранее добавленных данных.\n",
    "\n",
    "Для вычисления статистик используйте библиотеку numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe8269a-911d-400a-9f76-845548794cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "class SequentialTester:\n",
    "    def __init__(\n",
    "        self, metric_name, time_column_name,\n",
    "        alpha, beta, pdf_one, pdf_two\n",
    "    ):\n",
    "        \"\"\"Создаём класс для проверки гипотезы о равенстве средних тестом Вальда.\n",
    "\n",
    "        Предполагается, что среднее значение метрики у распределения альтернативной\n",
    "        гипотезы с плотность pdf_two больше.\n",
    "\n",
    "        :param metric_name: str, название стобца со значениями измерений.\n",
    "        :param time_column_name: str, названия столбца с датой и временем измерения.\n",
    "        :param alpha: float, допустимая ошибка первого рода.\n",
    "        :param beta: float, допустимая ошибка второго рода.\n",
    "        :param pdf_one: function, функция плотности распределения метрики при H0.\n",
    "        :param pdf_two: function, функция плотности распределения метрики при H1.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.time_column_name = time_column_name\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.pdf_one = pdf_one\n",
    "        self.pdf_two = pdf_two\n",
    "        \n",
    "        # YOUR_CODE_HERE\n",
    "        self.data_control = pd.DataFrame()\n",
    "        self.data_pilot   = pd.DataFrame()\n",
    "\n",
    "    def run_test(self, data_control, data_pilot):\n",
    "        \"\"\"Запускаем новый тест, проверяет гипотезу о равенстве средних.\n",
    "        \n",
    "        :param data_control: pd.DataFrame, данные контрольной группы.\n",
    "        :param data_pilot: pd.DataFrame, данные пилотной группы.\n",
    "        \n",
    "        :return (result, length):\n",
    "            result: float,\n",
    "                0 - отклоняем H1,\n",
    "                1 - отклоняем H0,\n",
    "                0.5 - недостаточно данных для принятия решения\n",
    "            length: int, сколько потребовалось данных для принятия решения. Если данных \n",
    "                недостаточно, то возвращает текущее кол-во данных. Кол-во данных - это\n",
    "                кол-во элементов в одном из наборов data_control или data_pilot.\n",
    "                Гарантируется, что они равны.\n",
    "        \"\"\"\n",
    "        # YOUR_CODE_HERE\n",
    "        \n",
    "        # Сохраняем данные.Будут как reference\n",
    "        if 0 == self.data_control.shape[0]:\n",
    "            data_control[self.time_column_name] = pd.to_datetime(data_control[self.time_column_name])\n",
    "            data_pilot[self.time_column_name]   = pd.to_datetime(data_pilot[self.time_column_name])\n",
    "            self.data_control = pd.concat([self.data_control, data_control], axis=0)\n",
    "            self.data_pilot   = pd.concat([self.data_pilot, data_pilot], axis=0)\n",
    "        else:\n",
    "            print(f\"run_test: WARNING: Using pre-saved data: shape={self.data_control.shape}\")\n",
    "        \n",
    "        return self._test_sequential_wald(\n",
    "            data_one = self.data_control[self.metric_name].to_numpy(), \n",
    "            data_two = self.data_pilot[self.metric_name].to_numpy(),\n",
    "            pdf_one = self.pdf_one,\n",
    "            pdf_two = self.pdf_two,\n",
    "            alpha = self.alpha,\n",
    "            beta = self.beta)\n",
    "\n",
    "    \n",
    "    def add_data(self, data_control, data_pilot):\n",
    "        \"\"\"Добавляет новые данные, проверяет гипотезу о равенстве средних.\n",
    "        \n",
    "        Гарантируется, что данные новые и не дублируют ранее добавленные.\n",
    "        \n",
    "        :param data_control: pd.DataFrame, новые данные контрольной группы.\n",
    "        :param data_pilot: pd.DataFrame, новые данные пилотной группы.\n",
    "        \n",
    "        :return (result, length):\n",
    "            result: float,\n",
    "                0 - отклоняем H1,\n",
    "                1 - отклоняем H0,\n",
    "                0.5 - недостаточно данных для принятия решения\n",
    "            length: int, сколько потребовалось данных для принятия решения. Если данных \n",
    "                недостаточно, то возвращает текущее кол-во данных. Кол-во данных - это\n",
    "                кол-во элементов в одном из наборов data_control или data_pilot.\n",
    "                Гарантируется, что они равны.\n",
    "        \"\"\"\n",
    "        # YOUR_CODE_HERE\n",
    "        #print(f\"Before: {st.data_control.shape=}, {st.data_pilot.shape}\")\n",
    "        self.data_control = self._add_data_2_df1(self.data_control, data_control, self.time_column_name)\n",
    "        self.data_pilot   = self._add_data_2_df1(self.data_pilot, data_pilot, self.time_column_name)\n",
    "        #print(f\"After: {st.data_control.shape=}, {st.data_pilot.shape}\")\n",
    " \n",
    "        return self.run_test(self.data_control, self.data_pilot)\n",
    "\n",
    "        \n",
    "    # helpers\n",
    "    def _add_data_2_df1(self, df1, df2, time_column_name) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Добавляет в df1 новые данные из df2. \"новые\" - это те, у которых ts > df1_max_ts\n",
    "        \"\"\"\n",
    "        df1_max_ts = df1[time_column_name].max()\n",
    "        df2[time_column_name] = pd.to_datetime(df2[time_column_name])\n",
    "        mask = (df2[time_column_name] > df1_max_ts)\n",
    "        df1 = pd.concat([df1, df2[mask]],ignore_index=True).drop_duplicates()\n",
    "        #print(df1)\n",
    "        return df1\n",
    "\n",
    "    def _test_sequential_wald(self, data_one, data_two, pdf_one, pdf_two, alpha, beta):\n",
    "        \"\"\"Последовательно проверяет отличие по мере поступления данных.\n",
    "    \n",
    "        pdf_one, pdf_two - функции плотности распределения при нулевой и альтернативной гипотезах\n",
    "    \n",
    "        Возвращает 1, если были найдены значимые отличия, иначе - 0. И кол-во объектов при принятии решения.\n",
    "        \"\"\"\n",
    "        lower_bound = np.log(beta / (1 - alpha))\n",
    "        upper_bound = np.log((1 - beta) / alpha)\n",
    "    \n",
    "        min_len = min([len(data_one), len(data_two)])\n",
    "        data_one = data_one[:min_len]\n",
    "        data_two = data_two[:min_len]\n",
    "        delta_data = data_two - data_one\n",
    "    \n",
    "        pdf_one_values = pdf_one(delta_data)\n",
    "        pdf_two_values = pdf_two(delta_data)\n",
    "    \n",
    "        z = np.cumsum(np.log(pdf_two_values / pdf_one_values))\n",
    "    \n",
    "        indexes_lower = np.arange(min_len)[z < lower_bound]\n",
    "        indexes_upper = np.arange(min_len)[z > upper_bound]\n",
    "        first_index_lower = indexes_lower[0] if len(indexes_lower) > 0 else min_len + 1\n",
    "        first_index_upper = indexes_upper[0] if len(indexes_upper) > 0 else min_len + 1\n",
    "    \n",
    "        if first_index_lower < first_index_upper:\n",
    "            return 0, first_index_lower + 1\n",
    "        elif first_index_lower > first_index_upper:\n",
    "            return 1, first_index_upper + 1\n",
    "        else:\n",
    "            return 0.5, min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9396576f-0ce3-4a92-a8ad-86d789c365cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Создаем генератор (источник) данных\n",
    "#\n",
    "\n",
    "MEAN = 10\n",
    "EFFECT = 1.03\n",
    "STD = 1\n",
    "ALPHA = 0.05\n",
    "BETA = 0.2\n",
    "\n",
    "START_TS = '2022-01-01 00:00'            # Timestamp начала эксперимента\n",
    "metric_name = 'value'           # название столбца со значениями\n",
    "time_column_name = 'ts'         # название столбца с датой и временем измерения\n",
    "\n",
    "def pdf_one(x):\n",
    "    \"\"\"Функция плотности разницы средних при верности нулевой гипотезы.\"\"\"\n",
    "    return stats.norm.pdf(x, 0, np.sqrt(2) * STD)\n",
    "\n",
    "def pdf_two(x):\n",
    "    \"\"\"Функция плотности разницы средних при верности альтернативной гипотезы.\"\"\"\n",
    "    return stats.norm.pdf(x, MEAN * (EFFECT-1), np.sqrt(2) * STD)\n",
    "\n",
    "def create_df(data_ts:np.array, data:np.array, time_column_name:str=time_column_name, metric_name:str=metric_name) -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    df[time_column_name]=data_ts\n",
    "    df[metric_name]=data\n",
    "    df[time_column_name] = df[time_column_name].dt.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    return df\n",
    "\n",
    "def generate_samples(start_ts = START_TS, \n",
    "                     sample_size=10, \n",
    "                     sample_interval=10, \n",
    "                     time_column_name:str=time_column_name, \n",
    "                     metric_name:str=metric_name) -> tuple:\n",
    "\n",
    "    data_a = np.random.normal(MEAN, STD, sample_size)\n",
    "    data_b = np.random.normal(MEAN * EFFECT, STD, sample_size)\n",
    "\n",
    "    data_ts = []\n",
    "    start_ts = datetime.datetime.strptime(start_ts, \"%Y-%m-%d %H:%M\")\n",
    "    for i in range(sample_size):\n",
    "        delta = datetime.timedelta(minutes = sample_interval*i)\n",
    "        data_ts.append(start_ts + delta)\n",
    "\n",
    "    data_control= create_df(data_ts, data_a)\n",
    "    data_pilot  = create_df(data_ts, data_b) \n",
    "    \n",
    "    return data_control, data_pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c769f6-7bd6-4e82-9dff-94bdf4e473da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_tester = SequentialTester(metric_name = metric_name,\n",
    "                                     time_column_name = time_column_name,\n",
    "                                     alpha = ALPHA,\n",
    "                                     beta = BETA,\n",
    "                                     pdf_one = pdf_one,\n",
    "                                     pdf_two = pdf_two)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c210a5-98f1-4c8c-8b9d-15667bae0eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_control, data_pilot = generate_samples(sample_size=5)\n",
    "\n",
    "seq_tester.run_test(data_control, data_pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6616fd5b-16ab-4022-b60d-85cb003938d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_test: WARNING: Using pre-saved data: shape=(15, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_control, data_pilot = generate_samples(sample_size=15)\n",
    "seq_tester.add_data(data_control, data_pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d254f855-9dab-47ad-a2dd-95dfba1685d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: st.data_control.shape=(30, 2), (30, 2)\n",
      "After: st.data_control.shape=(100, 2), (100, 2)\n",
      "run_test: WARNING: Using pre-saved data: shape=(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 70)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_data_2_df1(df1, df2, time_column_name = time_column_name) -> pd.DataFrame:\n",
    "    df1_max_ts = df1[time_column_name].max()\n",
    "    df2[time_column_name] = pd.to_datetime(df2[time_column_name])\n",
    "    mask = (df2[time_column_name] > df1_max_ts)\n",
    "    df1 = pd.concat([df1, df2[mask]],ignore_index=True).drop_duplicates()\n",
    "    #print(df1)\n",
    "    return df1\n",
    "\n",
    "print(f\"Before: {st.data_control.shape=}, {st.data_pilot.shape}\")\n",
    "\n",
    "st.data_control = add_data_2_df1(st.data_control, data_control)\n",
    "st.data_pilot   = add_data_2_df1(st.data_pilot, data_control)\n",
    "\n",
    "print(f\"After: {st.data_control.shape=}, {st.data_pilot.shape}\")\n",
    "\n",
    "\n",
    "st.run_test(st.data_control, st.data_pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dda09205-3e23-4721-a231-5de2f38e621a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                   ts      value\n",
       " 0 2022-01-01 00:00:00  11.478448\n",
       " 1 2022-01-01 00:10:00   9.856376\n",
       " 2 2022-01-01 00:20:00  11.885028\n",
       " 3 2022-01-01 00:30:00  10.018110\n",
       " 4 2022-01-01 00:40:00  11.411409\n",
       " 5 2022-01-01 00:50:00  10.759531\n",
       " 6 2022-01-01 01:00:00  11.376440\n",
       " 7 2022-01-01 01:10:00   7.681917\n",
       " 8 2022-01-01 01:20:00  10.653524\n",
       " 9 2022-01-01 01:30:00   9.100738,\n",
       "                    ts      value\n",
       " 0 2022-01-01 00:00:00  10.782323\n",
       " 1 2022-01-01 00:10:00  11.341916\n",
       " 2 2022-01-01 00:20:00  10.456278\n",
       " 3 2022-01-01 00:30:00  11.168543\n",
       " 4 2022-01-01 00:40:00  10.944976\n",
       " 5 2022-01-01 00:50:00  10.759531\n",
       " 6 2022-01-01 01:00:00  11.376440\n",
       " 7 2022-01-01 01:10:00   7.681917\n",
       " 8 2022-01-01 01:20:00  10.653524\n",
       " 9 2022-01-01 01:30:00   9.100738)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.data_control, st.data_pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2402e1b1-221a-4e38-b8d3-6b99cf32edae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2), (10, 2), (15, 2))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_data\n",
    "\n",
    "\n",
    "data_control_union= pd.concat([st.data_control, data_control],ignore_index=True).drop_duplicates()\n",
    "data_pilot_union = pd.concat([st.data_pilot, data_pilot],ignore_index=True).drop_duplicates()\n",
    "\n",
    "st.data_pilot.shape, data_pilot.shape, data_pilot_union.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e9517-63f1-4251-af9c-c45f11abd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union= pd.concat([df1, df2],ignore_index=True).drop_duplicates()\n",
    "df_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af8f4120-6631-4376-932a-e64063eeaecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 624)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.run_test(data_control, data_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a682fc24-a12b-442f-9214-79bc7fa3e373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run_test\n",
    "def run_test(data_control, data_pilot) -> tuple:\n",
    "    \n",
    "    return st.test_sequential_wald(data_one = data_control[metric_name].to_numpy(), \n",
    "                     data_two = data_pilot[metric_name].to_numpy(),\n",
    "                     pdf_one = st.pdf_one,\n",
    "                     pdf_two = st.pdf_two,\n",
    "                     alpha = st.alpha,\n",
    "                     beta = st.beta)\n",
    "\n",
    "run_test(data_control, data_pilot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
